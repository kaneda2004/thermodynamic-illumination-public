{
  "experiment": "RES-286: Two-Stage Sampling Generalization",
  "hypothesis": "Two-stage sampling generalizes beyond CPPNs to other neural network priors",
  "status": "REFUTED",
  "config": {
    "n_generators": 20,
    "order_target": 0.4,
    "stage1_budgets": [50, 100],
    "image_size": 32
  },
  "initial_results": {
    "mlp_speedup_mean": 2.0,
    "cppn_speedup_mean": 2.05,
    "superficial_conclusion": "generalizes (but misleading)"
  },
  "diagnostic_findings": {
    "issue_1_easy_target": {
      "finding": "Target=0.4 is trivially easy for MLP",
      "evidence": {
        "mlp_pct_hitting_04_from_init": 9.2,
        "cppn_pct_hitting_04_from_init": 0,
        "mlp_mean_init_order": 0.159,
        "cppn_mean_init_order": 0.063
      },
      "explanation": "With n_live=100, P(at least one MLP hits 0.4) ≈ 99.998%. 2.0× speedup is just n_live ratio (100/50), not real benefit."
    },
    "issue_2_stage2_hurts_mlp": {
      "finding": "When Stage 2 is actually needed, two-stage HURTS MLP",
      "evidence": {
        "target_07_trials": 20,
        "stage2_needed": 10,
        "stage2_mean_speedup": 0.38,
        "stage2_helps_count": "0/10"
      },
      "explanation": "PCA manifold learned from moderate-order samples doesn't point toward high-order solutions"
    },
    "issue_3_pca_variance": {
      "finding": "MLP weight space has much higher intrinsic dimension than CPPN",
      "evidence": {
        "cppn_params": 5,
        "cppn_pca_5_components_variance": 1.0,
        "cppn_components_for_90pct": 3,
        "mlp_params": 2433,
        "mlp_pca_5_components_variance": 0.305,
        "mlp_components_for_90pct": 39
      },
      "explanation": "5 PCA components capture 100% of CPPN variance but only 30.5% of MLP variance"
    },
    "issue_4_more_pca_doesnt_help": {
      "finding": "Increasing PCA components doesn't fix MLP",
      "evidence": {
        "pca_5_s2_speedup": 0.46,
        "pca_20_s2_speedup": 0.44,
        "pca_50_s2_speedup": 0.85
      },
      "explanation": "Even 50 components (96% variance) hurts. The manifold from Stage 1 samples doesn't lead to high-order targets."
    }
  },
  "root_cause": "Two-stage sampling requires LOW INTRINSIC DIMENSION. CPPN (5 params) satisfies this; MLP (2433 params, ~40D intrinsic) does not.",
  "conclusion": "Two-stage sampling is NOT architecture-general. It works for low-dimensional priors (CPPN) but fails for high-dimensional priors (MLP). The technique is intrinsic-dimension-specific, not just CPPN-specific.",
  "implications_for_paper": {
    "claim_scope": "Narrow from 'works for neural priors' to 'works for low-dimensional priors'",
    "cppn_specificity": "Partially. CPPN's 5-param structure is key, but any low-D prior would work.",
    "generalization_path": "Test on other low-D architectures (small MLPs, hypernetworks with low-rank constraints)"
  },
  "raw_data": {
    "mlp_order_distribution": {
      "mean": 0.159,
      "std": 0.160,
      "median": 0.070,
      "p90": 0.386,
      "p99": 0.714
    },
    "cppn_order_distribution": {
      "mean": 0.063,
      "std": 0.074,
      "median": 0.020,
      "p90": 0.170,
      "max": 0.389
    },
    "speedup_arrays": {
      "mlp_all_speedups": [
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        1.8518518518518519,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        0.2331002331002331,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0
      ],
      "mlp_best_speedups": [
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0,
        2.0
      ],
      "cppn_all_speedups": [
        0.3816793893129771,
        0.16666666666666666,
        2.0,
        0.16666666666666666,
        0.994579945799458,
        3.67,
        0.5909090909090909,
        0.5416666666666666,
        0.5818181818181818,
        6.4,
        0.4032258064516129,
        2.0,
        0.18181818181818182,
        0.49261083743842365,
        1.694915254237288,
        2.0,
        0.6090909090909091,
        0.9029649595687331,
        1.360655737704918,
        2.0080645161290325,
        0.43859649122807015,
        2.0,
        1.639344262295082,
        1.3333333333333333,
        0.7963636363636364,
        2.380434782608696,
        0.49636363636363634,
        0.455,
        0.5763636363636364,
        2.598360655737705,
        0.373134328358209,
        0.6097560975609756,
        0.28,
        0.36930455635491605,
        0.9781818181818182,
        3.5866666666666664,
        2.5491803278688523,
        6.22,
        0.6018181818181818,
        0.5516666666666666
      ],
      "cppn_best_speedups": [
        0.3816793893129771,
        2.0,
        3.67,
        0.5909090909090909,
        6.4,
        2.0,
        0.49261083743842365,
        2.0,
        0.9029649595687331,
        2.0080645161290325,
        2.0,
        1.639344262295082,
        2.380434782608696,
        0.49636363636363634,
        2.598360655737705,
        0.6097560975609756,
        0.36930455635491605,
        3.5866666666666664,
        6.22,
        0.6018181818181818
      ]
    }
  }
}
