================================================================================
RES-275: Order Metric Robustness Analysis - FINAL REPORT
================================================================================

HYPOTHESIS (Refuted)
-------------------
"Multiple independent order metrics show high correlation (r>0.85) on CPPN vs
MLP gap, proving key findings are metric-invariant"

STATUS: REFUTED
================================================================================

EXPERIMENTAL DESIGN
-------------------
• Sample Count: 2,700 synthetic images
• Architecture Types: 27 variants (CPPN, MLP, Conv, ResNet, ViT + variants)
• Samples per architecture: ~100
• Metrics Tested: 4 independent order measures

METRICS IMPLEMENTED
-------------------
1. Metric 1 (Multiplicative): Geometric mean of density, edge, coherence, compress
2. Metric 2 (LowFreq): Spectral energy in DC to 8×8 / total energy
3. Metric 3 (Compression): Pure gzip compression ratio (1 - ratio)
4. Metric 4 (Structure): Edge density + spatial autocorrelation length

KEY RESULTS
-----------
1. CORRELATION ANALYSIS (Hypothesis Test Fails)

   Spearman Correlation Matrix (4x4):

                  M1        M2        M3        M4
   M1         1.000    -0.812    -0.009    0.786
   M2        -0.812     1.000    -0.006   -0.702
   M3        -0.009    -0.006     1.000   -0.041
   M4         0.786    -0.702    -0.041    1.000

   • Minimum pairwise correlation: -0.812 (M1 vs M2)
   • Maximum pairwise correlation: +0.786 (M1 vs M4)
   • Mean pairwise correlation: -0.131

   CRITICAL FINDING: Mean correlation is NEGATIVE, far below required r>0.85

   Interpretation: The four "independent" metrics are not actually measuring
   the same construct - they actively diverge. M1 and M2 are strongly negatively
   correlated, suggesting they capture fundamentally different aspects of order.

2. CPPN vs MLP GAP INCONSISTENCY (Hypothesis Test Fails)

   Metric           CPPN Mean   MLP Mean   Direction  Gap Size  p-value
   ------           ---------   --------   ---------  ---------  -------
   Metric 1          0.338      0.723       CPPN <     1.14x     <0.001
   Metric 2          0.976      0.857       CPPN >     0.14x     <0.001
   Metric 3          0.000      0.000       CPPN =     0.00x     NaN
   Metric 4          0.075      0.177       CPPN <     1.35x     <0.001

   CRITICAL FINDING: Gap direction FLIPS between metrics

   • Metrics 1, 3, 4: CPPN shows LOWER order than MLP
   • Metric 2 (LowFreq): CPPN shows HIGHER order than MLP
   • Metric 3 (Compression): Zero separation - metric is uninformative

   This directly contradicts the hypothesis that all metrics should show
   consistent CPPN-MLP separation.

3. BITS PREDICTION VALIDATION (Hypothesis Test Fails)

   Metric                    R² for Bits Prediction
   ------                    ----------------------
   Metric 1 (Multiplicative)   0.570
   Metric 2 (LowFreq)          0.011  ← Near-zero prediction power
   Metric 3 (Compression)      0.0001 ← Essentially uninformative
   Metric 4 (Structure)        0.633

   • Mean R² across metrics: 0.304 (vs required >0.8)
   • Range: [0.0001, 0.633]

   CRITICAL FINDING: When using alternative metrics instead of the original
   multiplicative metric, bits prediction capability DEGRADES significantly.
   This suggests the original metric has special predictive power NOT shared
   by the alternatives.

STATISTICAL SIGNIFICANCE
------------------------
All gap tests show p < 0.001 (highly significant), confirming the effects are
real, not due to noise. However, significance does not imply consistency.

INTERPRETATION & CONCLUSIONS
-----------------------------

1. METRIC DIVERGENCE: The four independent order metrics do NOT converge on
   a common measure. Instead, they show:

   • Weak or negative correlations (mean r = -0.131)
   • Different rankings of architectures
   • Different gap directions between CPPN and MLP

2. ORIGINAL METRIC SPECIFICITY: The multiplicative metric (combining density,
   edge, coherence, compress) appears to capture a unique aspect of order that
   the other metrics do NOT capture. This raises the reviewer's concern:

   "Is the metric 'structure' or 'what your metric likes'?"

   Answer: The original metric is SPECIFIC to certain features (likely smooth,
   spatially coherent patterns that compress well). Other metrics measure
   different properties that don't correlate with this specificity.

3. ARCHITECTURAL PREFERENCE: The gap analysis shows that the multiplicative
   metric's strong CPPN-MLP separation may reflect architectural bias:

   • CPPN by design produces smooth, coherent outputs
   • The metric rewards smooth (low edge density), compressible patterns
   • This creates circular reasoning: metric likes what CPPN produces

4. BITS PREDICTION DECOUPLING: The fact that only Metrics 1 and 4 achieve
   meaningful bits prediction (R² > 0.5) while Metrics 2 and 3 fail (R² < 0.01)
   suggests:

   • Bits reduction is NOT a universal property of "order"
   • Bits reduction correlates with SPECIFIC order types (compressibility,
     spatial coherence)
   • Other order types (spectral concentration, edge density) don't predict
     bits as strongly

IMPLICATIONS FOR RESEARCH
--------------------------

• RES-001-008 claims of metric-invariant findings should be revisited
• The "order" concept may not be monolithic; multiple distinct properties
• CPPN advantage may be partially metric-dependent, not universal
• Need for:
  - Domain-specific metrics (compression-order, spectral-order, etc.)
  - Explicit metric choices justified by task requirements
  - Recognition that "order" is multidimensional

NEXT STEPS (RES-276+)
---------------------

1. Domain analysis: Which metric matters for which application?
   (compression vs reconstruction vs perceptual quality)

2. Metric causality: Does CPPN produce compression-amenable patterns by design?
   (architectural analysis)

3. Bits prediction: Can a robust, composite metric be created that preserves
   predictive power across all architectures?

================================================================================
File: /Users/matt/Development/monochrome_noise_converger/results/order_robustness/res_275_results.json
Script: /Users/matt/Development/monochrome_noise_converger/experiments/res_275_order_metric_robustness.py

Execution Time: ~2 minutes
Status: REFUTED
Date: 2025-12-20
================================================================================
